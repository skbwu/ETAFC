{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3558f264",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import sys, copy, os, shutil\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# load in our true case counts\n",
    "cases = pd.read_csv(\"processed/weekly_cases.csv\")\n",
    "cases.date = pd.to_datetime(cases.date)\n",
    "cases.set_index(\"date\", inplace=True)\n",
    "\n",
    "# our set of locations\n",
    "locations = pd.read_csv(\"processed/locations.csv\")\n",
    "\n",
    "# color-blind friendly colors\n",
    "colors = ['#377eb8', '#ff7f00', '#4daf4a',\n",
    "          '#f781bf', '#a65628', '#984ea3',\n",
    "          '#999999', '#e41a1c', '#dede00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5187b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what columns are we interested in?\n",
    "para_cols = [\"model\", \"fh\", \"log_trans\", \"num_nodes\", \"cluster_mech\", \n",
    "             \"num_lags\", \"shuffle\", \"local_reg\", \"neighbor_reg\"]\n",
    "mMAE_cols = [f\"mMAE_{loc}\" for loc in locations.location_key.values] + [\"mMAE_tot\"]\n",
    "sMAE_cols = [f\"sMAE_{loc}\" for loc in locations.location_key.values] + [\"sMAE_tot\"]\n",
    "\n",
    "# create our dataframe \n",
    "logs = pd.DataFrame(data=None, columns=para_cols + mMAE_cols + sMAE_cols)\n",
    "\n",
    "# let's use a common test set for all horizons just to keep things fair and comparable\n",
    "pred_start_shared = pd.Timestamp(2021, 2, 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "821b63ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41a6f0c555a24e54ac36d0c532fd86c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5040 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# iterate thru all TGCN trials\n",
    "for fname in tqdm(sorted([f for f in os.listdir(\"results/tgcn\") if \".csv\" in f])):\n",
    "    \n",
    "    # specify what model we're using\n",
    "    model = \"tgcn\"\n",
    "    \n",
    "    # unpack the settings for TGCN\n",
    "    fh, log_trans, num_nodes, cluster_mech, num_lags, shuffle = tuple([s.split(\"=\")[1] \\\n",
    "                                                                       for s in fname\\\n",
    "                                                                       .replace(\".csv\", \"\").split(\"_\")])\n",
    "\n",
    "    # convert to appropriate data types\n",
    "    fh, num_nodes, cluster_mech, num_lags = int(fh), int(num_nodes), int(cluster_mech), int(num_lags)\n",
    "    log_trans = True if log_trans == \"True\" else False\n",
    "    shuffle = True if shuffle == \"True\" else False\n",
    "    \n",
    "    # load our predictions, too + extract out the start and end\n",
    "    preds = pd.read_csv(f\"results/tgcn/{fname}\")\n",
    "    preds.date = pd.to_datetime(preds.date)\n",
    "    preds.set_index(\"date\", inplace=True)\n",
    "    pred_start, pred_end = preds.index[0], preds.index[-1]\n",
    "    \n",
    "    # overwrite the pred_start + truncate\n",
    "    pred_start = pred_start_shared\n",
    "    preds = preds.loc[pred_start_shared :]\n",
    "    \n",
    "    # compute the naive predictions\n",
    "    naive_start = pred_start - relativedelta(days=7*fh)\n",
    "    naive_end = pred_end - relativedelta(days=7*fh)\n",
    "    naive_preds = cases.loc[naive_start : naive_end].set_index(preds.index)\n",
    "    \n",
    "    # compute scaled MAE (justify because don't want to penalize overprediction egregiously, as in MSE)\n",
    "    truth = cases.loc[pred_start : pred_end]\n",
    "    nMAEs = np.abs(truth - naive_preds).mean() # naive MAE\n",
    "    mMAEs = np.abs(truth - preds).mean() # model MAE\n",
    "    sMAEs = mMAEs / nMAEs # the scaled version -- how much better do we do than persistence?\n",
    "    \n",
    "    # for cross-compatibility with the linear models\n",
    "    local_reg, neighbor_reg = np.nan, np.nan\n",
    "    \n",
    "    # store both the scaled and unscaled versions!\n",
    "    row = [model, fh, log_trans, num_nodes, cluster_mech, num_lags, shuffle, local_reg, neighbor_reg]\n",
    "    row += (list(mMAEs.values) + [mMAEs.mean()])\n",
    "    row += (list(sMAEs.values) + [sMAEs.mean()])\n",
    "    logs.loc[len(logs.index)] = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b36b1d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83e9c5ff8886496a9050af3e6b074c4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5040 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# iterate thru all DCRNN trials\n",
    "for fname in tqdm(sorted([f for f in os.listdir(\"results/dcrnn\") if \".csv\" in f])):\n",
    "    \n",
    "    # specify what model we're using\n",
    "    model = \"dcrnn\"\n",
    "    \n",
    "    # unpack the settings for DCRNN\n",
    "    fh, log_trans, num_nodes, cluster_mech, num_lags, shuffle = tuple([s.split(\"=\")[1] \\\n",
    "                                                                       for s in fname\\\n",
    "                                                                       .replace(\".csv\", \"\").split(\"_\")])\n",
    "\n",
    "    # convert to appropriate data types\n",
    "    fh, num_nodes, cluster_mech, num_lags = int(fh), int(num_nodes), int(cluster_mech), int(num_lags)\n",
    "    log_trans = True if log_trans == \"True\" else False\n",
    "    shuffle = True if shuffle == \"True\" else False\n",
    "    \n",
    "    # load our predictions, too + extract out the start and end\n",
    "    preds = pd.read_csv(f\"results/dcrnn/{fname}\")\n",
    "    preds.date = pd.to_datetime(preds.date)\n",
    "    preds.set_index(\"date\", inplace=True)\n",
    "    pred_start, pred_end = preds.index[0], preds.index[-1]\n",
    "    \n",
    "    # overwrite the pred_start + truncate\n",
    "    pred_start = pred_start_shared\n",
    "    preds = preds.loc[pred_start_shared :]\n",
    "    \n",
    "    # compute the naive predictions\n",
    "    naive_start = pred_start - relativedelta(days=7*fh)\n",
    "    naive_end = pred_end - relativedelta(days=7*fh)\n",
    "    naive_preds = cases.loc[naive_start : naive_end].set_index(preds.index)\n",
    "    \n",
    "    # compute scaled MAE (justify because don't want to penalize overprediction egregiously, as in MSE)\n",
    "    truth = cases.loc[pred_start : pred_end]\n",
    "    nMAEs = np.abs(truth - naive_preds).mean() # naive MAE\n",
    "    mMAEs = np.abs(truth - preds).mean() # model MAE\n",
    "    sMAEs = mMAEs / nMAEs # the scaled version -- how much better do we do than persistence?\n",
    "    \n",
    "    # for cross-compatibility with the linear models\n",
    "    local_reg, neighbor_reg = np.nan, np.nan\n",
    "    \n",
    "    # store both the scaled and unscaled versions!\n",
    "    row = [model, fh, log_trans, num_nodes, cluster_mech, num_lags, shuffle, local_reg, neighbor_reg]\n",
    "    row += (list(mMAEs.values) + [mMAEs.mean()])\n",
    "    row += (list(sMAEs.values) + [sMAEs.mean()])\n",
    "    logs.loc[len(logs.index)] = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e1c708b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fa6e5d695d94ccb97c8b3bc16f37640",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4032 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# iterate thru all linear trials\n",
    "for fname in tqdm(sorted([f for f in os.listdir(\"results/linear\") if \".csv\" in f])):\n",
    "    \n",
    "    # specify what model we're using\n",
    "    model = \"linear\"\n",
    "    \n",
    "    # unpack the settings for our linear one\n",
    "    fh, log_trans, num_lags, cluster_mech, reg_scheme = tuple([s.split(\"=\")[1] \\\n",
    "                                                               for s in fname\\\n",
    "                                                               .replace(\".csv\", \"\").split(\"_\")])\n",
    "\n",
    "    # convert to appropriate types\n",
    "    fh, num_lags, cluster_mech = int(fh), int(num_lags), int(cluster_mech)\n",
    "    log_trans = True if log_trans == \"True\" else False\n",
    "\n",
    "    # unpack the local + neighbor regularization factors\n",
    "    local_reg, neighbor_reg = np.array(reg_scheme.split(\"+\")).astype(int)\n",
    "    \n",
    "    # load our predictions, too + extract out the start and end\n",
    "    preds = pd.read_csv(f\"results/linear/{fname}\")\n",
    "    preds.date = pd.to_datetime(preds.date)\n",
    "    preds.set_index(\"date\", inplace=True)\n",
    "    pred_start, pred_end = preds.index[0], preds.index[-1]\n",
    "    \n",
    "    # overwrite the pred_start + truncate\n",
    "    pred_start = pred_start_shared\n",
    "    preds = preds.loc[pred_start_shared :]\n",
    "    \n",
    "    # compute the naive predictions\n",
    "    naive_start = pred_start - relativedelta(days=7*fh)\n",
    "    naive_end = pred_end - relativedelta(days=7*fh)\n",
    "    naive_preds = cases.loc[naive_start : naive_end].set_index(preds.index)\n",
    "    \n",
    "    # compute scaled MAE (justify because don't want to penalize overprediction egregiously, as in MSE)\n",
    "    truth = cases.loc[pred_start : pred_end]\n",
    "    nMAEs = np.abs(truth - naive_preds).mean() # naive MAE\n",
    "    mMAEs = np.abs(truth - preds).mean() # model MAE\n",
    "    sMAEs = mMAEs / nMAEs # the scaled version -- how much better do we do than persistence?\n",
    "    \n",
    "    # for cross-compatibility with the graph neural network models\n",
    "    num_nodes, shuffle = np.nan, np.nan\n",
    "    \n",
    "    # store both the scaled and unscaled versions!\n",
    "    row = [model, fh, log_trans, num_nodes, cluster_mech, num_lags, shuffle, local_reg, neighbor_reg]\n",
    "    row += (list(mMAEs.values) + [mMAEs.mean()])\n",
    "    row += (list(sMAEs.values) + [sMAEs.mean()])\n",
    "    logs.loc[len(logs.index)] = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9b83cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save our logs files\n",
    "logs.to_csv(\"performance_logs.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (Afterburner)\n",
   "language": "python",
   "name": "afterburner"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
